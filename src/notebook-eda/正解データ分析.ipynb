{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 正解データ分析\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# 1. ライブラリ導入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc, gridspec\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "from math import *\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rcParams['font.family'] = ['Hiragino Sans']\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. 調布市　阪上さん加工の正解データ（06_fin.json）　\n",
    "### 1-1. 各時間帯におけるPoIの滞在分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/y-osamu/study/poi_sim/data/processed/true_data/06_fin.json' # 調布市の正解データ\n",
    "file_path_base = '/Users/y-osamu/study/poi_sim/data/processed/true_data/'\n",
    "\n",
    "\n",
    "true_files = sorted(glob.glob(os.path.join(file_path_base,'*.json')))\n",
    "true_files\n",
    "\n",
    "# 2列3行のサブプロットを作成\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# グラフの位置を調整\n",
    "axs = axs.flatten()\n",
    "\n",
    "# 各ファイルについて処理\n",
    "for i, file in enumerate(true_files):\n",
    "    file_name = os.path.basename(file)[:2]  # Extracts the file name from the path\n",
    "    \n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    df = pd.DataFrame(list(data.items()), columns=[\"category\", \"population\"])\n",
    "\n",
    "    # メッシュ番号を抽出\n",
    "    df[\"Mesh Number\"] = df[\"category\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    df[\"category\"] = df[\"category\"].apply(lambda x: x.split(\"_\")[1])\n",
    "    df = df[~df[\"category\"].isin([\"Home\", \"Move\"])]\n",
    "    \n",
    "    # サブプロットにデータを描画\n",
    "    axs[i].barh(df[\"category\"], df[\"population\"], color=\"skyblue\")\n",
    "    axs[i].set_xlabel(\"Population\")\n",
    "    axs[i].set_ylabel(\"Category\")\n",
    "    axs[i].set_title(f\"At {file_name} o'clock : Population Distribution by Industry\")\n",
    "    axs[i].grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# レイアウト調整\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 1-2. 各時点のメッシュとPoIの分布　アニメーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# アニメーション描画する関数\n",
    "def make_heatmap_animation(true_files):\n",
    "    \"\"\"\n",
    "    毎回 新しい Figure / Animation を作って返す\n",
    "    → 何回表示しても warning が出ない\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(22, 15))\n",
    "    cbar_shown = False\n",
    "\n",
    "    def update_heatmap(frame):\n",
    "        nonlocal cbar_shown\n",
    "\n",
    "        with open(true_files[frame], 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        df = pd.DataFrame(list(data.items()), columns=[\"key\", \"value\"])\n",
    "        df[\"mesh\"] = df[\"key\"].str.split(\"_\").str[0]\n",
    "        df[\"category\"] = df[\"key\"].str.split(\"_\").str[1]\n",
    "        df = df[~df[\"category\"].isin([\"Home\", \"Move\"])]\n",
    "        df = df.pivot(index=\"category\", columns=\"mesh\", values=\"value\").fillna(0)\n",
    "\n",
    "        ax.clear()\n",
    "        sns.heatmap(\n",
    "            df,\n",
    "            cmap=\"Blues\",\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cbar=not cbar_shown,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        if not cbar_shown:\n",
    "            cbar_shown = True\n",
    "\n",
    "        ax.set_xlabel(\"メッシュ\")\n",
    "        ax.set_ylabel(\"カテゴリー\")\n",
    "        ax.set_title(\n",
    "            f\"At {os.path.basename(true_files[frame])} : メッシュ × カテゴリー 人口分布\"\n",
    "        )\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "    # ★ frames は range が最強\n",
    "    ani = FuncAnimation(\n",
    "        fig,\n",
    "        update_heatmap,\n",
    "        frames=range(len(true_files)),\n",
    "        repeat=False\n",
    "    )\n",
    "\n",
    "    # ★ Notebook 安定化のため必須\n",
    "    plt.close(fig)\n",
    "\n",
    "    return HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap_animation(true_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 1-3. 予測データの分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 阪上さん予測データ\n",
    "\n",
    "file_path = '/Users/y-osamu/study/poi_sim/data/processed/true_data/06_fin.json' # 調布市の正解データ\n",
    "file_path_base = '/Users/y-osamu/study/poi_sim/data/processed/output_meshid_poi/8'\n",
    "\n",
    "\n",
    "true_files = sorted(glob.glob(os.path.join(file_path_base,'*.json')))\n",
    "\n",
    "# 現在のフレーム（ファイル）のデータを読み込む\n",
    "with open(true_files[0], 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(list(data.items()), columns=[\"key\", \"value\"])\n",
    "# keyごとに処理\n",
    "result_dfs = {}\n",
    "for key, values in zip(df[\"key\"], df[\"value\"]):\n",
    "    aggregated = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for entry in values:\n",
    "        mesh, category = entry.split(\"_\")\n",
    "        aggregated[mesh][category] += 1\n",
    "    \n",
    "    # データフレームに変換\n",
    "    rows = []\n",
    "    for mesh, categories in aggregated.items():\n",
    "        for category, count in categories.items():\n",
    "            rows.append([mesh, category, count])\n",
    "    \n",
    "    result_dfs[key] = pd.DataFrame(rows, columns=[\"Mesh\", \"Category\", \"Count\"])\n",
    "    \n",
    "for key, df in result_dfs.items():\n",
    "    heatmap_data = df.pivot(index=\"Category\", columns=\"Mesh\", values=\"Count\").fillna(0)\n",
    "\n",
    "    # ヒートマップを描画\n",
    "    plt.figure(figsize=(16,12))\n",
    "    sns.heatmap(heatmap_data, annot=True, cmap=\"Blues\", fmt=\".0f\")\n",
    "    plt.title(f\"wolrd {key} : mesh × PoI\")\n",
    "    plt.xlabel(\"Mesh\")\n",
    "    plt.ylabel(\"Category\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遷移確率行列の　分析　\n",
    "\n",
    "trans_prob_mat_dir = '/Users/y-osamu/study/poi_sim/data/processed/new'\n",
    "mat_files = sorted(glob.glob(os.path.join(trans_prob_mat_dir,'*.npy')))\n",
    "\n",
    "# 740×７４０ 547600　個の要素\n",
    "    \n",
    "# .npyファイルをロード\n",
    "matrix = np.load(mat_files[0])\n",
    "\n",
    "# すべての値を取得\n",
    "values = matrix.flatten()\n",
    "\n",
    "# ヒストグラムの描画\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(values, bins=50, log=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.xlabel(\"確率\")\n",
    "plt.ylabel(\"頻度\")\n",
    "plt.title(\"確率の分布\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(matrix, cmap=\"Blues\", vmax=0.1)  \n",
    "plt.title(\"大まかな遷移確率の分布\")\n",
    "plt.xlabel(\"横\")\n",
    "plt.ylabel(\"縦\")\n",
    "plt.show()\n",
    "\n",
    "nonzero_ratio = np.count_nonzero(matrix) / matrix.size\n",
    "print(f\"Non-zero ratio: {nonzero_ratio:.4%}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/osamu/study/sakagami/Sakagami_code/sakagami_processsing/true_data/06_fin.json' # 調布市の正解データ\n",
    "file_path_base = '/Users/osamu/study/sakagami/Sakagami_code/sakagami_processsing/true_data/'\n",
    "\n",
    "\n",
    "true_files = sorted(glob.glob(os.path.join(file_path_base,'*.json')))\n",
    "\n",
    "# 現在のフレーム（ファイル）のデータを読み込む\n",
    "with open(true_files[0], 'r', encoding='utf-8') as f:\n",
    "    data_6am = json.load(f)\n",
    "    \n",
    "# 現在のフレーム（ファイル）のデータを読み込む\n",
    "with open(true_files[1], 'r', encoding='utf-8') as f:\n",
    "    data_7am = json.load(f)\n",
    "    \n",
    "df_6am = pd.DataFrame(list(data_6am.items()), columns=[\"category\", \"population\"])\n",
    "\n",
    "# メッシュ番号を抽出\n",
    "df_6am[\"Mesh Number\"] = df_6am[\"category\"].apply(lambda x: x.split(\"_\")[0])\n",
    "df_6am[\"category\"] = df_6am[\"category\"].apply(lambda x: x.split(\"_\")[1])\n",
    "df_6am\n",
    "\n",
    "data_7am = pd.DataFrame(list(data_7am.items()), columns=[\"category\", \"population\"])\n",
    "\n",
    "# メッシュ番号を抽出\n",
    "data_7am[\"Mesh Number\"] = data_7am[\"category\"].apply(lambda x: x.split(\"_\")[0])\n",
    "data_7am[\"category\"] = data_7am[\"category\"].apply(lambda x: x.split(\"_\")[1])\n",
    "data_7am\n",
    "\n",
    "data_7am"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 阪上さんの遷移確率実行結果を再現\n",
    "    \n",
    "- 東京都調布市の大カテゴリーの遷移確率\n",
    "    - 対象時間:8時から9時\n",
    "    - 対象期間:2019.02.01 - 2019.04.15\n",
    "    - 分類方法:山田の分類方法\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data のデータの解析\n",
    "df = pd.read_csv(\"../data/20190201.csv\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/201902_week1.csv\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "df_home = pd.read_csv(\"../data/201902_week1_home.csv\")\n",
    "df_home = df_home.drop(columns=[\"Unnamed: 0\"])\n",
    "df_output = pd.read_csv(\"../data/201902_week1_output.csv\")\n",
    "df_output = df_output.drop(columns=[\"Unnamed: 0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/201902*output*\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poi_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
